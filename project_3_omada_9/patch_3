diff -ruN linux-3.14.62-orig/arch/x86/syscalls/syscall_32.tbl linux-3.14.62-dev/arch/x86/syscalls/syscall_32.tbl
--- linux-3.14.62-orig/arch/x86/syscalls/syscall_32.tbl	2016-02-25 11:59:45.000000000 -0800
+++ linux-3.14.62-dev/arch/x86/syscalls/syscall_32.tbl	2017-05-11 13:17:30.868132506 -0700
@@ -359,3 +359,5 @@
 350	i386	finit_module		sys_finit_module
 351	i386	sched_setattr		sys_sched_setattr
 352	i386	sched_getattr		sys_sched_getattr
+353  	i386	slob_get_total_alloc_m  sys_slob_get_total_alloc_m   	
+354     i386    slob_get_total_free_mem sys_slob_get_total_free_mem
\ No newline at end of file
diff -ruN linux-3.14.62-orig/include/linux/syscalls.h linux-3.14.62-dev/include/linux/syscalls.h
--- linux-3.14.62-orig/include/linux/syscalls.h	2016-02-25 11:59:45.000000000 -0800
+++ linux-3.14.62-dev/include/linux/syscalls.h	2017-05-11 13:18:45.880132478 -0700
@@ -855,4 +855,6 @@
 asmlinkage long sys_kcmp(pid_t pid1, pid_t pid2, int type,
 			 unsigned long idx1, unsigned long idx2);
 asmlinkage long sys_finit_module(int fd, const char __user *uargs, int flags);
+asmlinkage long sys_slob_get_total_alloc_m(void);
+asmlinkage long sys_slob_get_total_free_mem(void);
 #endif
diff -ruN "linux-3.14.62-orig/kernel/long slob_get_total_free_mem.c" "linux-3.14.62-dev/kernel/long slob_get_total_free_mem.c"
--- "linux-3.14.62-orig/kernel/long slob_get_total_free_mem.c"	1969-12-31 16:00:00.000000000 -0800
+++ "linux-3.14.62-dev/kernel/long slob_get_total_free_mem.c"	2017-05-11 13:10:48.204132655 -0700
@@ -0,0 +1,6 @@
+#include <linux/kernel.h>
+#include <linux/syscalls.h>
+extern long *call_free; 
+SYSCALL_DEFINE0(slob_get_total_free_mem){
+  return *call_free;
+}
diff -ruN linux-3.14.62-orig/kernel/Makefile linux-3.14.62-dev/kernel/Makefile
--- linux-3.14.62-orig/kernel/Makefile	2016-02-25 11:59:45.000000000 -0800
+++ linux-3.14.62-dev/kernel/Makefile	2017-05-11 13:24:28.632132351 -0700
@@ -10,7 +10,7 @@
 	    kthread.o sys_ni.o posix-cpu-timers.o \
 	    hrtimer.o nsproxy.o \
 	    notifier.o ksysfs.o cred.o reboot.o \
-	    async.o range.o groups.o smpboot.o
+	    async.o range.o groups.o smpboot.o slob_get_total_alloc_m.o slob_get_total_free_mem.o
 
 ifdef CONFIG_FUNCTION_TRACER
 # Do not trace debug files and internal ftrace files
diff -ruN linux-3.14.62-orig/kernel/slob_get_total_alloc_m.c linux-3.14.62-dev/kernel/slob_get_total_alloc_m.c
--- linux-3.14.62-orig/kernel/slob_get_total_alloc_m.c	1969-12-31 16:00:00.000000000 -0800
+++ linux-3.14.62-dev/kernel/slob_get_total_alloc_m.c	2017-05-11 09:08:28.894167343 -0700
@@ -0,0 +1,6 @@
+#include <linux/kernel.h>
+#include <linux/syscalls.h>
+extern long *call_total; 
+SYSCALL_DEFINE0(slob_get_total_alloc_m){
+  return *call_total;
+}
diff -ruN linux-3.14.62-orig/kernel/slob_get_total_free_mem.c linux-3.14.62-dev/kernel/slob_get_total_free_mem.c
--- linux-3.14.62-orig/kernel/slob_get_total_free_mem.c	1969-12-31 16:00:00.000000000 -0800
+++ linux-3.14.62-dev/kernel/slob_get_total_free_mem.c	2017-05-11 13:27:24.676132285 -0700
@@ -0,0 +1,6 @@
+#include <linux/kernel.h>
+#include <linux/syscalls.h>
+extern long *call_free; 
+SYSCALL_DEFINE0(slob_get_total_free_mem){
+  return *call_free;
+}
diff -ruN linux-3.14.62-orig/mm/slob.c linux-3.14.62-dev/mm/slob.c
--- linux-3.14.62-orig/mm/slob.c	2016-02-25 11:59:45.000000000 -0800
+++ linux-3.14.62-dev/mm/slob.c	2017-05-12 07:05:41.555455929 -0700
@@ -69,7 +69,7 @@
 #include <linux/kmemleak.h>
 
 #include <trace/events/kmem.h>
-
+#include <linux/linkage.h>
 #include <linux/atomic.h>
 
 #include "slab.h"
@@ -97,16 +97,21 @@
  */
 #define SLOB_BREAK1 256
 #define SLOB_BREAK2 1024
+#define SLOB_BESTFIT
 static LIST_HEAD(free_slob_small);
 static LIST_HEAD(free_slob_medium);
 static LIST_HEAD(free_slob_large);
-
+static int times=0;
+static long free_space=0;
+static long total_space=0;
+long *call_total=&total_space;
+long *call_free=&free_space;
 /*
  * slob_page_free: true for pages on free_slob_pages list.
  */
 static inline int slob_page_free(struct page *sp)
 {
-	return PageSlobFree(sp);
+		return PageSlobFree(sp);
 }
 
 static void set_slob_page_free(struct page *sp, struct list_head *list)
@@ -208,7 +213,9 @@
 {
 	if (current->reclaim_state)
 		current->reclaim_state->reclaimed_slab += 1 << order;
+
 	free_pages((unsigned long)b, order);
+
 }
 
 /*
@@ -216,16 +223,48 @@
  */
 static void *slob_page_alloc(struct page *sp, size_t size, int align)
 {
-	slob_t *prev, *cur, *aligned = NULL;
-	int delta = 0, units = SLOB_UNITS(size);
-
+  slob_t *prev, *cur, *aligned = NULL,*best_block,*best_block_prev,*best_block_alligned=NULL;
+  int delta = 0, units = SLOB_UNITS(size),best_block_delta=0;
+  int min_avail;
+  int i=0;
+  slobidx_t avail;
+  if(times==6000)
+    printk("Slob Alloc candidate block sizes: ");
 	for (prev = NULL, cur = sp->freelist; ; prev = cur, cur = slob_next(cur)) {
-		slobidx_t avail = slob_units(cur);
+		avail = slob_units(cur);
 
 		if (align) {
 			aligned = (slob_t *)ALIGN((unsigned long)cur, align);
 			delta = aligned - cur;
 		}
+#ifdef SLOB_BESTFIT
+		if((avail>= units + delta)&&(i==0||(avail-units-delta<min_avail))){
+		  if(times==6000)
+		     printk(" %d ",avail);
+		  i=1;
+		  best_block=cur;
+		  best_block_prev=prev;
+		  best_block_alligned=aligned;
+		  best_block_delta=delta;
+		  min_avail=avail-units-delta;
+		}
+		if (slob_last(cur))
+		  break;
+	}
+	if(times==6000){
+	  printk("\n");
+	  times=0;
+	}else
+	  times++;
+	if(i==0)
+	  return NULL;
+	cur=best_block;
+	prev=best_block_prev;
+	aligned=best_block_alligned;
+	delta=best_block_delta;
+	avail=units+delta+min_avail;
+	printk("slob alloc Best fit:%d\n",avail);
+#endif
 		if (avail >= units + delta) { /* room enough? */
 			slob_t *next;
 
@@ -244,6 +283,7 @@
 					set_slob(prev, slob_units(prev), next);
 				else
 					sp->freelist = next;
+			     
 			} else { /* fragment */
 				if (prev)
 					set_slob(prev, slob_units(prev), cur + units);
@@ -257,22 +297,55 @@
 				clear_slob_page_free(sp);
 			return cur;
 		}
+#ifndef SLOB_BESTFIT
 		if (slob_last(cur))
 			return NULL;
-	}
+             }
+#endif
 }
+static int  slob_page_find(struct page *sp, size_t size, int align)
+{
+  slob_t *prev, *cur, *aligned = NULL,*best_block,*best_block_prev,*best_block_alligned=NULL;
+  int delta = 0, units = SLOB_UNITS(size),best_block_delta=0;
+  slobidx_t min_avail;
+  int i=0;
+  slobidx_t avail;
+
+	for (prev = NULL, cur = sp->freelist; ; prev = cur, cur = slob_next(cur)) {
+		avail = slob_units(cur);
 
+		if (align) {
+			aligned = (slob_t *)ALIGN((unsigned long)cur, align);
+			delta = aligned - cur;
+		}
+		if((avail>= units + delta)){//&&(i==0||(avail-units-delta<min_avail))){
+		  i=1;
+		  
+		  return 1;
+		 
+		}
+		if (slob_last(cur))
+		  return 0;
+	}
+	if(i==0)
+	  return 0;
+	//	else
+	//	  return (min_avail);
+}
 /*
  * slob_alloc: entry point into the slob allocator.
  */
 static void *slob_alloc(size_t size, gfp_t gfp, int align, int node)
 {
-	struct page *sp;
+  struct page *sp,*min_sp;
 	struct list_head *prev;
 	struct list_head *slob_list;
-	slob_t *b = NULL;
+	slob_t *b = NULL,*bestfit=NULL;
 	unsigned long flags;
-
+	slob_t fit;
+	slobidx_t min_sp_units=-1;
+	int smallest=0;
+	int i=0;
 	if (size < SLOB_BREAK1)
 		slob_list = &free_slob_small;
 	else if (size < SLOB_BREAK2)
@@ -282,6 +355,7 @@
 
 	spin_lock_irqsave(&slob_lock, flags);
 	/* Iterate through each partially free page, try to find room */
+	printk("Slob Request: %d\n",SLOB_UNITS(size));
 	list_for_each_entry(sp, slob_list, list) {
 #ifdef CONFIG_NUMA
 		/*
@@ -295,24 +369,63 @@
 		if (sp->units < SLOB_UNITS(size))
 			continue;
 
-		/* Attempt to alloc */
+#ifndef SLOB_BESTFIT		/* Attempt to alloc */
 		prev = sp->list.prev;
 		b = slob_page_alloc(sp, size, align);
+#else
+		smallest=  slob_page_find(sp, size, align);
+		if((smallest!=0)&&(min_sp_units<(sp->units-SLOB_UNITS(size))||i==0)){
+		  //if(min_sp_units<sp->units-SLOB_UNITS(size)||i==0){
+		    i=1;
+		    min_sp=sp;
+		    min_sp_units=sp->units-SLOB_UNITS(size);
+//		      break;
+		      //}
+		  
+		      // else{
+		      // continue;
+		      }
+	
+	
+	}
+	if(i!=0)
+	  b = slob_page_alloc(min_sp, size, align);
+	/*	if (!b)
+			continue;
+		break;
+	*/
+	
+#endif
+#ifndef SLOB_BESTFIT 
 		if (!b)
 			continue;
-
+	
 		/* Improve fragment distribution and reduce our average
 		 * search time by starting our next search here. (see
 		 * Knuth vol 1, sec 2.5, pg 449) */
+		
 		if (prev != slob_list->prev &&
-				slob_list->next != prev->next)
-			list_move_tail(slob_list, prev->next);
+		    slob_list->next != prev->next)
+		  list_move_tail(slob_list, prev->next);
 		break;
+              }
+#endif 
+        free_space=0;
+        list_for_each_entry(sp,  &free_slob_small, list) {
+	  free_space+=sp->units;
+	}
+         list_for_each_entry(sp,  &free_slob_medium, list) {
+	   free_space+=sp->units;
+	}
+         list_for_each_entry(sp,  &free_slob_large, list) {
+	   free_space+=sp->units;
 	}
 	spin_unlock_irqrestore(&slob_lock, flags);
 
 	/* Not enough space: must allocate a new page */
-	if (!b) {
+
+            if (!b) {
+	      
 		b = slob_new_pages(gfp & ~__GFP_ZERO, 0, node);
 		if (!b)
 			return NULL;
@@ -321,6 +434,7 @@
 
 		spin_lock_irqsave(&slob_lock, flags);
 		sp->units = SLOB_UNITS(PAGE_SIZE);
+		total_space+=sp->units;
 		sp->freelist = b;
 		INIT_LIST_HEAD(&sp->list);
 		set_slob(b, SLOB_UNITS(PAGE_SIZE), b + SLOB_UNITS(PAGE_SIZE));
@@ -356,8 +470,10 @@
 
 	if (sp->units + units == SLOB_UNITS(PAGE_SIZE)) {
 		/* Go directly to page allocator. Do not pass slob allocator */
-		if (slob_page_free(sp))
-			clear_slob_page_free(sp);
+	  if (slob_page_free(sp)){
+	    	total_space-=sp->units;
+	    clear_slob_page_free(sp);
+	  }
 		spin_unlock_irqrestore(&slob_lock, flags);
 		__ClearPageSlab(sp);
 		page_mapcount_reset(sp);
diff -ruN linux-3.14.62-orig/security/tomoyo/builtin-policy.h linux-3.14.62-dev/security/tomoyo/builtin-policy.h
--- linux-3.14.62-orig/security/tomoyo/builtin-policy.h	1969-12-31 16:00:00.000000000 -0800
+++ linux-3.14.62-dev/security/tomoyo/builtin-policy.h	2017-05-05 05:17:17.615312222 -0700
@@ -0,0 +1,12 @@
+static char tomoyo_builtin_profile[] __initdata =
+"";
+static char tomoyo_builtin_exception_policy[] __initdata =
+"initialize_domain /sbin/modprobe from any\n"
+"initialize_domain /sbin/hotplug from any\n"
+"";
+static char tomoyo_builtin_domain_policy[] __initdata =
+"";
+static char tomoyo_builtin_manager[] __initdata =
+"";
+static char tomoyo_builtin_stat[] __initdata =
+"";
diff -ruN linux-3.14.62-orig/security/tomoyo/policy/exception_policy.conf linux-3.14.62-dev/security/tomoyo/policy/exception_policy.conf
--- linux-3.14.62-orig/security/tomoyo/policy/exception_policy.conf	1969-12-31 16:00:00.000000000 -0800
+++ linux-3.14.62-dev/security/tomoyo/policy/exception_policy.conf	2017-05-05 05:17:17.515312223 -0700
@@ -0,0 +1,2 @@
+initialize_domain /sbin/modprobe from any
+initialize_domain /sbin/hotplug from any
